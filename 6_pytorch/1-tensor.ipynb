{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "PyTorch是基于Python的科学计算包，其旨在服务两类场合：\n",
    "* 替代NumPy发挥GPU潜能\n",
    "* 提供了高度灵活性和效率的深度学习平台\n",
    "\n",
    "PyTorch设计简洁，容易入门，本部分先介绍一些PyTorch的基础知识，让大家能够对PyTorch有一个大致的了解，并能够用PyTorch搭建一个简单的神经网络，然后在深入学习如何使用PyTorch实现各类网络结构。在学习过程，可能部分内容暂时不太理解，可先不予以深究，后续的课程将会对此进行深入讲解。\n",
    "\n",
    "\n",
    "\n",
    "![PyTorch Demo](imgs/PyTorch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor基本用法\n",
    "\n",
    "张量(Tensor)是一种专门的数据结构，非常类似于数组和矩阵。在PyTorch中，使用张量来编码模型的输入和输出，以及模型的参数。\n",
    "\n",
    "张量类似于`NumPy`的`ndarray`，不同之处在于张量可以在GPU或其他硬件加速器上运行。事实上，张量和NumPy数组通常可以共享相同的底层内存，从而消除了复制数据的需要(请参阅使用NumPy的桥接)。张量还针对自动微分进行了优化，在Autograd部分中看到更多关于这一点的内介绍。\n",
    "\n",
    "PyTorch基础的数据是张量(Tensor)，PyTorch 的很多操作好 NumPy 都是类似的，但是因为其能够在 GPU 上运行，所以有着比 NumPy 快很多倍的速度。本节内容主要包括 PyTorch 中的基本元素 Tensor 和 Variable 及其操作方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tensor定义与生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个 numpy ndarray\n",
    "numpy_tensor = np.random.randn(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用下面两种方式将numpy的ndarray转换到tensor上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6102,  0.0836, -1.3426, -1.0950,  0.3379,  1.2605, -0.7757, -0.5921,\n",
       "         -1.3449,  0.3962, -0.4818, -1.1418,  0.1370,  1.3309, -1.0032,  0.8597,\n",
       "          1.0776,  0.7736,  0.5551, -1.5840],\n",
       "        [ 0.0886, -0.0464,  0.0801, -1.1247,  0.7748, -0.4999,  0.0648,  0.5163,\n",
       "          1.2706,  0.5618,  0.1259, -1.2189, -0.6585, -0.9329, -0.6004, -0.4276,\n",
       "          0.2789, -0.0953,  0.0740, -0.4697],\n",
       "        [-0.0758, -0.3135,  1.7796,  0.8236, -1.6153,  1.2830, -0.9118, -1.6770,\n",
       "         -1.1650,  1.1811, -1.1449,  0.0299,  0.4844,  0.1248, -1.5596, -1.9826,\n",
       "         -0.1547, -0.8708,  0.8458, -0.5622],\n",
       "        [ 0.4287, -1.3753,  1.1535,  0.8381, -0.1025,  1.0018, -0.8653,  0.1768,\n",
       "         -0.7614,  2.2579, -1.1263,  1.5185,  1.2413, -0.5175,  0.2510, -1.9549,\n",
       "         -0.3212, -0.4222,  0.5857, -0.3750],\n",
       "        [-1.5206,  0.3396, -0.3352,  1.6381,  0.2351,  0.7146, -1.2693,  2.1835,\n",
       "          0.4490, -0.4977,  1.1643, -0.2862, -0.7194, -0.1130,  0.1851,  0.6409,\n",
       "         -0.6567, -1.1177, -0.2681,  2.6444],\n",
       "        [ 0.3260, -2.5563, -0.6876,  0.2737, -0.1789, -0.1197,  1.1745,  0.2749,\n",
       "          1.0663,  0.5220,  1.8237, -1.4168, -0.1803,  1.7733,  0.5749, -0.9812,\n",
       "         -0.6346,  0.2211,  0.7156,  1.1195],\n",
       "        [ 1.3371, -1.2685, -0.6516, -0.0948, -0.1142, -1.9450,  1.0557, -1.3263,\n",
       "         -1.3389,  1.2293,  0.3922,  0.1506, -0.6684,  1.3135, -1.1515,  1.1071,\n",
       "          0.1776, -1.9510, -1.1809, -0.7406],\n",
       "        [-0.1944, -0.1302,  0.9722,  0.3542,  1.3825, -0.0841, -0.0313, -0.6345,\n",
       "          0.0256,  1.3840,  0.2759,  1.6995, -1.4833,  1.8134,  1.3491,  0.9334,\n",
       "          0.3327, -1.1879, -0.9789,  0.1923],\n",
       "        [ 0.6467,  0.4202, -0.6106,  0.6859,  0.2778,  0.9616,  0.5759, -1.4312,\n",
       "          0.0865, -1.8661, -1.3264, -0.1112,  0.5663, -0.4165, -0.3919,  0.5788,\n",
       "          1.3698,  0.6647,  1.0246, -0.3412],\n",
       "        [ 0.2041,  0.6331, -1.9039,  0.0530,  1.9217, -0.5628,  0.3047, -0.9514,\n",
       "         -1.9946, -0.3843, -1.1050, -0.3481, -0.5009,  0.0929,  0.9091, -0.9152,\n",
       "          2.5930,  0.6916, -0.9628,  0.7297]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_tensor1 = torch.tensor(numpy_tensor)\n",
    "pytorch_tensor2 = torch.from_numpy(numpy_tensor)\n",
    "\n",
    "pytorch_tensor1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用以上两种方法进行转换的时候，会直接将 NumPy ndarray 的数据类型转换为对应的 PyTorch Tensor 数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时也可以使用下面的方法将 `PyTorch Tensor` 转换为 `NumPy ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果 pytorch tensor 在 cpu 上\n",
    "numpy_array = pytorch_tensor1.numpy()\n",
    "\n",
    "# 如果 pytorch tensor 在 gpu 上\n",
    "numpy_array = pytorch_tensor1.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意 GPU 上的 Tensor 不能直接转换为 NumPy ndarray，需要使用`.cpu()`先将 GPU 上的 Tensor 转到 CPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PyTorch Tensor 使用 GPU 加速\n",
    "\n",
    "我们可以使用以下两种方式将 Tensor 放到 GPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "# 第一种方式是定义 cuda 数据类型\n",
    "dtype = torch.cuda.FloatTensor # 定义默认 GPU 的 数据类型\n",
    "gpu_tensor = torch.randn(10, 20).type(dtype)\n",
    "\n",
    "# 第二种方式更简单，推荐使用\n",
    "gpu_tensor = torch.randn(10, 20).cuda(0) # 将 tensor 放到第一个 GPU 上\n",
    "#gpu_tensor = torch.randn(10, 20).cuda(1) # 将 tensor 放到第二个 GPU 上\n",
    "\n",
    "print(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用第一种方式将 tensor 放到 GPU 上的时候会将数据类型转换成定义的类型，而是用第二种方式能够直接将 tensor 放到 GPU 上，类型跟之前保持一致\n",
    "\n",
    "推荐在定义 tensor 的时候就明确数据类型，然后直接使用第二种方法将 tensor 放到 GPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而将 tensor 放回 CPU 的操作如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_tensor = gpu_tensor.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor 属性的访问方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# 可以通过下面两种方式得到 tensor 的大小\n",
    "print(pytorch_tensor1.shape)\n",
    "print(pytorch_tensor1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的数据类型\n",
    "print(pytorch_tensor1.type())\n",
    "print(gpu_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的维度\n",
    "print(pytorch_tensor1.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的所有元素个数\n",
    "print(pytorch_tensor1.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor的操作\n",
    "Tensor 操作中的 API 和 NumPy 非常相似，如果熟悉 NumPy 中的操作，那么 tensor 基本操作是一致的，下面列举其中的一些操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 2)\n",
    "print(x) # 这是一个float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 将其转化为整形\n",
    "x = x.long()\n",
    "# x = x.type(torch.LongTensor)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 再将其转回 float\n",
    "x = x.float()\n",
    "# x = x.type(torch.FloatTensor)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0419, -0.6384,  0.7058],\n",
      "        [-0.0577,  1.4475,  1.6988],\n",
      "        [-1.1054, -2.5010,  0.9245],\n",
      "        [-0.3980,  1.0583, -0.0771]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 沿着行取最大值\n",
    "max_value, max_idx = torch.max(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8199, 1.7495, 0.8838, 1.0189])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一行的最大值\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一行最大值的下标\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8577,  1.2994,  1.5605,  1.9802])\n"
     ]
    }
   ],
   "source": [
    "# 沿着行对 x 求和\n",
    "sum_x = torch.sum(x, dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0.0419, -0.6384,  0.7058],\n",
      "         [-0.0577,  1.4475,  1.6988],\n",
      "         [-1.1054, -2.5010,  0.9245],\n",
      "         [-0.3980,  1.0583, -0.0771]]])\n"
     ]
    }
   ],
   "source": [
    "# 增加维度或者减少维度\n",
    "print(x.shape)\n",
    "x = x.unsqueeze(0) # 在第一维增加\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.unsqueeze(1) # 在第二维增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0.0419, -0.6384,  0.7058],\n",
      "         [-0.0577,  1.4475,  1.6988],\n",
      "         [-1.1054, -2.5010,  0.9245],\n",
      "         [-0.3980,  1.0583, -0.0771]]])\n"
     ]
    }
   ],
   "source": [
    "x = x.squeeze(0) # 减少第一维\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.squeeze() # 将 tensor 中所有的一维全部都去掉\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([4, 3, 5])\n",
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4, 5)\n",
    "print(x.shape)\n",
    "\n",
    "# 使用permute和transpose进行维度交换\n",
    "x = x.permute(1, 0, 2) # permute 可以重新排列 tensor 的维度\n",
    "print(x.shape)\n",
    "\n",
    "x = x.transpose(0, 2)  # transpose 交换 tensor 中的两个维度\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([12, 5])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 使用 view 对 tensor 进行 reshape\n",
    "x = torch.randn(3, 4, 5)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(-1, 5) # -1 表示任意的大小，5 表示第二维变成 5\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(3, 20) # 重新 reshape 成 (3, 20) 的大小\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1612,  2.3494,  1.6714, -3.0109],\n",
      "        [-0.4416,  0.5964,  0.5427, -0.2245],\n",
      "        [ 0.7276, -3.1390,  0.8543,  0.9866]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(3, 4)\n",
    "\n",
    "# 两个 tensor 求和\n",
    "z = x + y\n",
    "# z = torch.add(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 `inplace`操作\n",
    "\n",
    "PyTorch中大多数的操作都支持 `inplace` 操作，也就是可以直接对 tensor 进行操作而不需要另外开辟内存空间，方式非常简单，一般都是在操作的符号后面加`_`，比如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3, 3])\n",
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 3)\n",
    "print(x.shape)\n",
    "\n",
    "# unsqueeze 进行 inplace\n",
    "x.unsqueeze_(0)\n",
    "print(x.shape)\n",
    "\n",
    "# transpose 进行 inplace\n",
    "x.transpose_(1, 0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 3)\n",
    "y = torch.ones(3, 3)\n",
    "print(x)\n",
    "\n",
    "# add 进行 inplace\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 查阅[PyTorch的Tensor文档](http://pytorch.org/docs/tensors.html)了解 tensor 的数据类型，创建一个 float64、大小是 3 x 2、随机初始化的 tensor，将其转化为 numpy 的 ndarray，输出其数据类型\n",
    "* 查阅[PyTorch的Tensor文档](http://pytorch.org/docs/tensors.html)了解 tensor 更多的 API，创建一个 float32、4 x 4 的全为1的矩阵，将矩阵正中间 2 x 2 的矩阵，全部修改成2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "* [PyTorch官方说明文档](https://pytorch.org/docs/stable/)\n",
    "* http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "* http://cs231n.github.io/python-numpy-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
